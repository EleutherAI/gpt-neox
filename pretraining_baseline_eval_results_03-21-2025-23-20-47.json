{
    "results": {
        "piqa": {
            "acc,none": 0.7693144722524483,
            "acc_stderr,none": 0.009828959550983209,
            "acc_norm,none": 0.7780195865070729,
            "acc_norm_stderr,none": 0.009696120744662062
        }
    },
    "group_subtasks": {
        "piqa": []
    },
    "configs": {
        "piqa": {
            "task": "piqa",
            "dataset_path": "piqa",
            "dataset_kwargs": {
                "trust_remote_code": true
            },
            "training_split": "train",
            "validation_split": "validation",
            "doc_to_text": "Question: {{goal}}\nAnswer:",
            "doc_to_target": "label",
            "unsafe_code": false,
            "doc_to_choice": "{{[sol1, sol2]}}",
            "description": "",
            "target_delimiter": " ",
            "fewshot_delimiter": "\n\n",
            "num_fewshot": 0,
            "metric_list": [
                {
                    "metric": "acc",
                    "aggregation": "mean",
                    "higher_is_better": true
                },
                {
                    "metric": "acc_norm",
                    "aggregation": "mean",
                    "higher_is_better": true
                }
            ],
            "output_type": "multiple_choice",
            "repeats": 1,
            "should_decontaminate": true,
            "doc_to_decontamination_query": "goal",
            "metadata": {
                "version": 1.0
            }
        }
    },
    "versions": {
        "piqa": 1.0
    },
    "n-shot": {
        "piqa": 0
    },
    "higher_is_better": {
        "piqa": {
            "acc": true,
            "acc_norm": true
        }
    },
    "n-samples": {
        "piqa": {
            "original": 1838,
            "effective": 1838
        }
    },
    "config": {
        "model": "neox",
        "model_args": {
            "distributed_backend": "nccl",
            "local_rank": 0,
            "rank": 0,
            "lazy_mpu_init": false,
            "short_seq_prob": 0.1,
            "eod_mask_loss": false,
            "adlr_autoresume": false,
            "adlr_autoresume_interval": 1000,
            "seed": 1234,
            "onnx_safe": false,
            "deepscale": false,
            "deepscale_config": null,
            "deepspeed_mpi": false,
            "deepspeed_slurm": false,
            "user_script": "eval.py",
            "iteration": 40528,
            "do_train": null,
            "do_valid": null,
            "do_test": null,
            "global_num_gpus": 1,
            "text_gen_type": "unconditional",
            "precompute_model_name": null,
            "temperature": 0.0,
            "top_p": 0.0,
            "top_k": 0,
            "return_logits": false,
            "maximum_tokens": 64,
            "prompt_end": "\n",
            "sample_input_file": null,
            "sample_output_file": "samples.txt",
            "num_samples": 1,
            "recompute": false,
            "eval_results_prefix": "pretraining_baseline",
            "eval_tasks": [
                "piqa"
            ],
            "moe_top_k": 1,
            "use_tutel": false,
            "moe_num_experts": 1,
            "moe_loss_coeff": 0.1,
            "moe_train_capacity_factor": 1.0,
            "moe_eval_capacity_factor": 1.0,
            "moe_min_capacity": 4,
            "moe_token_dropping": false,
            "create_moe_param_group": true,
            "moe_use_residual": true,
            "moe_expert_parallel_size": 1,
            "moe_type": "megablocks",
            "moe_glu": false,
            "moe_lbl_in_fp32": false,
            "moe_jitter_eps": null,
            "enable_expert_tensor_parallelism": false,
            "use_wandb": true,
            "wandb_group": "0tmaizzg_f9qheuf4",
            "wandb_run_name": "pretraining_baseline_intermediate",
            "wandb_team": "eleutherai",
            "wandb_project": "AISI-Evals",
            "wandb_host": "https://api.wandb.ai",
            "wandb_init_all_ranks": false,
            "git_hash": "60753736",
            "log_dir": "logs",
            "tensorboard_dir": "tensorboard",
            "use_comet": null,
            "comet_workspace": null,
            "comet_project": null,
            "comet_experiment_name": null,
            "comet_tags": null,
            "comet_others": null,
            "comet_experiment": null,
            "peak_theoretical_tflops": null,
            "log_interval": 10,
            "log_grad_pct_zeros": false,
            "log_param_norm": false,
            "log_grad_norm": false,
            "log_optimizer_states": false,
            "log_gradient_noise_scale": false,
            "gradient_noise_scale_n_batches": 5,
            "gradient_noise_scale_cpu_offload": false,
            "memory_profiling": false,
            "memory_profiling_path": null,
            "profile": false,
            "profile_step_start": 10,
            "profile_step_stop": 12,
            "pipe_parallel_size": 1,
            "model_parallel_size": 1,
            "pipe_partition_method": "type:transformer|mlp",
            "world_size": 1,
            "is_pipe_parallel": true,
            "sequence_parallel": false,
            "expert_interval": 2,
            "data_path": null,
            "use_shared_fs": true,
            "train_data_paths": null,
            "train_label_data_paths": null,
            "train_reward_data_paths": null,
            "test_data_paths": null,
            "test_label_data_paths": null,
            "test_reward_data_paths": null,
            "valid_data_paths": null,
            "valid_label_data_paths": null,
            "valid_reward_data_paths": null,
            "pos_train_data_paths": null,
            "neg_train_data_paths": null,
            "pos_train_label_data_paths": null,
            "neg_train_label_data_paths": null,
            "pos_valid_data_paths": null,
            "neg_valid_data_paths": null,
            "pos_valid_label_data_paths": null,
            "neg_valid_label_data_paths": null,
            "pos_test_data_paths": null,
            "neg_test_data_paths": null,
            "pos_test_label_data_paths": null,
            "neg_test_label_data_paths": null,
            "train_data_weights": null,
            "valid_data_weights": null,
            "test_data_weights": null,
            "weight_by_num_documents": false,
            "weighted_sampler_alpha": 1.0,
            "data_impl": "mmap",
            "pack_impl": "packed",
            "dataset_impl": "gpt2",
            "train_impl": "normal",
            "dpo_fp32": true,
            "dpo_reference_free": false,
            "dpo_beta": 0.1,
            "kto_fp32": true,
            "kto_desirable_weight": 1.0,
            "kto_undesirable_weight": 1.0,
            "z_loss": 0.0,
            "kto_beta": 0.1,
            "fp32_reinforce": true,
            "kl_impl": "mse",
            "kl_div_beta": 0.1,
            "reinforce_leave_one_out": false,
            "allow_chopped": true,
            "mmap_warmup": false,
            "save": null,
            "s3_path": null,
            "s3_chunk_size": 104857600,
            "config_files": {
                "eval_aisi_single_node.yml": "{\n  # Tokens\n  # \"data_path\": \"/data/pretraining-mix/pretraining-mix_text_document\",\n  \"vocab_file\": \"/mnt/ssd-1/kyle/hf_neox_checkpoints/neox_tokenizer/tokenizer.json\",\n  \"tokenizer_type\": \"HFTokenizer\",\n  \"data_impl\": \"mmap\",\n\n  # Logging\n  \"checkpoint_validation_with_forward_pass\": False,\n  \"tensorboard_dir\": \"tensorboard\",\n  \"log_dir\": \"logs\",\n  \"log_interval\": 10,\n  \"steps_per_print\": 10,\n  \"wall_clock_breakdown\": true,\n  \"use_wandb\": True,\n  \"wandb_host\": \"https://api.wandb.ai\",\n  \"wandb_project\": \"AISI-Evals\",\n  \"wandb_team\": \"eleutherai\",\n  \"wandb_run_name\": \"pretraining_baseline_intermediate\",\n\n  # Distributed Training\n  # \"hostfile\": \"/workspace/hostfile\",\n  # \"deepspeed_mpi\": True,\n  # \"launcher\": \"openmpi\",\n  # \"deepspeed_extra_args\": { \"ssh_port\": 2222 },\n  \"master_port\": 1668,\n  \"pipe_parallel_size\": 1,\n  \"model_parallel_size\": 1,\n\n  # Training Duration\n  # 500B (tokens) / (4 (grad acc) * 32 (world size) * 16 (micro batch size) * 2048 (seq length))\n  \"train_iters\": 119209,\n  \"lr_decay_iters\": 119209,\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"split\": \"100,0,0\",\n\n  # Architecture\n  \"num_layers\": 32,\n  \"hidden_size\": 4096,\n  \"num_attention_heads\": 32,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"norm\": \"layernorm\",\n  \"pos_emb\": \"rotary\",\n  \"rotary_pct\": 0.25,\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": true,\n  \"output_layer_parallelism\": \"column\",\n  \"attention_config\": [[[\"flash\"], 32]],\n  \"scaled_upper_triang_masked_softmax_fusion\": true,\n  \"precision\": \"bfloat16\",\n  \"activation\": \"gelu\",\n  # \"activation\": \"swiglu\", TODO: Support SwiGLU\n\n  # Transformer Engine\n  \"te_columnparallel\": false,\n  \"te_rowparallel\": false,\n  \"te_layernorm_mlp\": true,\n  \"te_mha\": true,\n  \"te_fp8_format\": \"hybrid\",\n  \"te_fp8_wgrad\": false,\n  \"te_fp8_amax_history_len\": 1,\n  \"te_fp8_amax_compute_algo\": \"most_recent\",\n  \"te_fp8_margin\": 0,\n  \"te_fp8_mha\": false,\n\n  # Optimization\n  # 0.0003 is OLMo 2's peak learning rate\n  \"optimizer\":\n    {\n      \"type\": \"Adam\",\n      \"params\": { \"lr\": 0.0003, \"betas\": [0.9, 0.95], \"eps\": 1.0e-8 },\n    },\n  \"min_lr\": 0.000012,\n  \"zero_optimization\":\n    {\n      \"stage\": 1,\n      \"allgather_partitions\": true,\n      \"allgather_bucket_size\": 1260000000,\n      \"overlap_comm\": true,\n      \"reduce_scatter\": true,\n      \"reduce_bucket_size\": 1260000000,\n      \"contiguous_gradients\": true,\n      \"cpu_offload\": false,\n    },\n  \"train_micro_batch_size_per_gpu\": 16,\n  \"gradient_accumulation_steps\": 4,\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.1,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # Checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": true,\n  \"synchronize_each_layer\": true,\n  \"checkpoint_factor\": 2000,\n  # \"save\": \"/checkpoints/pretraining_baseline\",\n  # \"checkpoint\": \"global_step10728\",\n  \"iteration\": 40528,\n  \"load\": \"/mnt/ssd-1/kyle/hf/hub/models--EleutherAI--filtering-for-danger-pretraining_baseline-neox/snapshots/37051b8172940cd639bf2f77614bbcf6a5a98685\",\n\n  # Evaluation\n  \"eval_iters\": 0,\n  \"eval_interval\": 5,\n  \"eval_results_prefix\": \"pretraining_baseline\",\n  # TODO: Add automatic evals for next runs\n  #\"eval_tasks\": [\"wmdp_bio\"],\n  # \"do_valid\",\n  # \"eval_tasks\": [\"wmdp\", \"mmlu\", \"piqa\", \"arc-easy\", \"arc-challenge\", \"lambada\", \"hellaswag\"]\n}\n"
            },
            "load": "/mnt/ssd-1/kyle/hf/hub/models--EleutherAI--filtering-for-danger-pretraining_baseline-neox/snapshots/37051b8172940cd639bf2f77614bbcf6a5a98685",
            "checkpoint_validation_with_forward_pass": false,
            "checkpoint_scale": "linear",
            "checkpoint_factor": 2000,
            "extra_save_iters": null,
            "no_save_optim": false,
            "no_save_rng": false,
            "no_load_optim": true,
            "no_load_rng": false,
            "finetune": false,
            "batch_size": 16,
            "train_iters": 119209,
            "train_epochs": null,
            "eval_iters": 0,
            "keep_last_n_checkpoints": null,
            "eval_interval": 5,
            "split": "100,0,0",
            "vocab_file": "/mnt/ssd-1/kyle/hf_neox_checkpoints/neox_tokenizer/tokenizer.json",
            "merge_file": null,
            "num_workers": 2,
            "exit_interval": null,
            "attention_dropout": 0.0,
            "hidden_dropout": 0.0,
            "weight_decay": 0.1,
            "checkpoint_activations": false,
            "checkpoint_num_layers": 1,
            "deepspeed_activation_checkpointing": true,
            "contiguous_checkpointing": false,
            "checkpoint_in_cpu": false,
            "synchronize_each_layer": true,
            "profile_backward": false,
            "partition_activations": false,
            "clip_grad": 1.0,
            "hysteresis": 2,
            "dynamic_loss_scale": true,
            "loss_scale": null,
            "loss_scale_window": 1000.0,
            "min_scale": 1.0,
            "char_level_ppl": false,
            "use_mup": false,
            "coord_check": false,
            "save_base_shapes": false,
            "base_shapes_file": null,
            "mup_init_scale": 1.0,
            "mup_attn_temp": 1.0,
            "mup_output_temp": 1.0,
            "mup_embedding_mult": 1.0,
            "mup_rp_embedding_mult": 1.0,
            "mup_width_scale": 2,
            "tokenizer_type": "HFTokenizer",
            "padded_vocab_size": 50304,
            "optimizer_type": "adam",
            "use_bnb_optimizer": false,
            "zero_stage": 1,
            "zero_reduce_scatter": true,
            "zero_contiguous_gradients": true,
            "zero_reduce_bucket_size": 1260000000,
            "zero_allgather_bucket_size": 1260000000,
            "lr": 0.001,
            "lr_decay_style": "cosine",
            "lr_decay_iters": 119209,
            "lr_decay_fraction": null,
            "min_lr": 1.2e-05,
            "warmup": 0.01,
            "override_lr_scheduler": false,
            "use_checkpoint_lr_scheduler": false,
            "precision": "bfloat16",
            "num_layers": 32,
            "hidden_size": 4096,
            "intermediate_size": null,
            "mlp_multiple_of": 1,
            "expansion_factor": null,
            "num_attention_heads": 32,
            "num_kv_heads": null,
            "seq_length": 2048,
            "sliding_window_width": null,
            "max_position_embeddings": 2048,
            "norm": "layernorm",
            "layernorm_fusion": false,
            "rmsnorm_fusion": false,
            "use_qk_layernorm": false,
            "layernorm_epsilon": 1e-05,
            "rms_norm_epsilon": 1e-08,
            "scalenorm_epsilon": 1e-08,
            "pos_emb": "rotary",
            "rpe_num_buckets": 32,
            "rpe_max_distance": 128,
            "opt_pos_emb_offset": 0,
            "no_weight_tying": true,
            "attention_config": [
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash",
                "flash"
            ],
            "sparsity_config": {},
            "num_unique_layers": null,
            "param_sharing_style": "grouped",
            "make_vocab_size_divisible_by": 128,
            "activation": "gelu",
            "use_flashattn_swiglu": false,
            "scaled_upper_triang_masked_softmax_fusion": true,
            "scaled_masked_softmax_fusion": false,
            "bias_gelu_fusion": false,
            "bias_dropout_fusion": false,
            "rope_fusion": false,
            "fp16_lm_cross_entropy": false,
            "init_method_std": 0.02,
            "apply_query_key_layer_scaling": false,
            "use_cpu_initialization": false,
            "attention_softmax_in_fp32": false,
            "rotary_pct": 0.25,
            "rotary_emb_base": 10000,
            "rotary_save_freqs_buffer": false,
            "init_method": "normal",
            "output_layer_init_method": "scaled_normal",
            "gmlp_attn_dim": 64,
            "gpt_j_residual": true,
            "gpt_j_tied": false,
            "use_bias_in_norms": true,
            "use_bias_in_attn_linear": true,
            "use_bias_in_mlp": true,
            "soft_prompt_tuning": null,
            "mamba_selective_scan_fusion": false,
            "mamba_causal_conv_fusion": false,
            "mamba_inner_func_fusion": false,
            "mamba_selective_fp32_params": true,
            "mamba_use_bias_in_conv": true,
            "mamba_use_bias_in_linears": false,
            "output_layer_parallelism": "column",
            "serve_model_weights": false,
            "weight_server_port": 6000,
            "online_dataserver_ips": "localhost",
            "online_dataserver_ports": 10000,
            "te_columnparallel": false,
            "te_rowparallel": false,
            "te_layernorm_mlp": true,
            "te_mha": true,
            "te_fp8_format": "hybrid",
            "te_fp8_wgrad": false,
            "te_fp8_amax_history_len": 1,
            "te_fp8_amax_compute_algo": "most_recent",
            "te_fp8_margin": 0,
            "te_fp8_mha": false,
            "dim_att": null,
            "head_size": null,
            "ffn_dim": null,
            "deepspeed": true,
            "train_batch_size": 64,
            "train_micro_batch_size_per_gpu": 16,
            "gradient_accumulation_steps": 4,
            "optimizer": {
                "params": {
                    "lr": 0.0
                }
            },
            "scheduler": null,
            "fp32_allreduce": false,
            "prescale_gradients": false,
            "gradient_predivide_factor": 1.0,
            "sparse_gradients": false,
            "fp16": null,
            "bf16": null,
            "amp": null,
            "gradient_clipping": 1.0,
            "zero_optimization": {
                "stage": 1,
                "allgather_partitions": true,
                "allgather_bucket_size": 1260000000,
                "overlap_comm": true,
                "reduce_scatter": true,
                "reduce_bucket_size": 1260000000,
                "contiguous_gradients": true,
                "cpu_offload": false
            },
            "curriculum_learning": null,
            "curriculum_seqlen": 0,
            "steps_per_print": 10,
            "wall_clock_breakdown": true,
            "dump_state": false,
            "flops_profiler": null,
            "communication_data_type": null,
            "autotuning": null,
            "activation_checkpointing": null,
            "sparse_attention": null,
            "data_efficiency": null,
            "tensorboard": null,
            "wandb": null,
            "csv_monitor": null,
            "elasticity": null,
            "comms_logger": null,
            "compression_training": null,
            "checkpoint": null,
            "data_types": null,
            "deepspeed_extra_args": {
                "bf16": {
                    "enabled": true
                }
            },
            "hostfile": null,
            "include": null,
            "exclude": null,
            "num_nodes": -1,
            "num_gpus": null,
            "master_port": 1668,
            "master_addr": null,
            "launcher": "pdsh",
            "force_multi": false,
            "autotuning_run": null,
            "no_ssh_check": false,
            "comment": null,
            "account": null
        },
        "batch_size": 16,
        "device": "cuda:0",
        "use_cache": false,
        "limit": null,
        "bootstrap_iters": 10000
    },
    "git_hash": "60753736"
}